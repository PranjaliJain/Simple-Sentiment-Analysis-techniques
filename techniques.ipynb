{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple sentiment analysis techniques in python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a guide to using the different techinques availble for sentiment analysis without training any data. Primarily these techniques only classify sentiments into positive and negative.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use some restaurant reviews as a small dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=[\"Food is good and not too expensive. Serving is just right. Ambience is nice too.\",\n",
    "        \"Fast service. Prices are reasonable and food is decent.\",\n",
    "        \"Loved the ambience, loved the food\",\n",
    "        \"Mushroom fried rice was tasty\",\n",
    "        \"Service - Little slow, probably because too many people.\",\n",
    "        \"The place is not easy to locate\",\n",
    "        \"Extremely long waiting time. Food is decent but definitely not worth the wait.\",\n",
    "        \"Used to be good. Soup was below average this time.\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we remove any non alphanumeric symbols. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tosentences(articles):\n",
    "    tokenizer = RegexpTokenizer(r'[\\w\\?\\.\\!\\'-]+')\n",
    "    tokens=[]\n",
    "    text=\"\"\n",
    "    \n",
    "    tokens=(tokenizer.tokenize(articles))\n",
    "    text=(\" \".join(tokens))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=[]\n",
    "for i in dataset:\n",
    "    query.append(tosentences(i))\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Food is good and not too expensive. Serving is just right. Ambience is nice too.',\n",
       " 'Fast service. Prices are reasonable and food is decent.',\n",
       " 'Loved the ambience loved the food',\n",
       " 'Mushroom fried rice was tasty',\n",
       " 'Service - Little slow probably because too many people.',\n",
       " 'The place is not easy to locate',\n",
       " 'Extremely long waiting time. Food is decent but definitely not worth the wait.',\n",
       " 'Used to be good. Soup was below average this time.']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using IBM Watson Tone Analyser API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we use the IBM Watson Tone Analyser API. To use this API, create a free account on IBM Cloud. Subscribe to the IBM Tone Analyser API. We are ready to use it for sentiment analysis now. This API is able to detect several emotions like happy,sad,joy,anger,fear,confidence and many more.\n",
    "Also, it gives specific tone name and score to each sentence in a given piece of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watson_developer_cloud import ToneAnalyzerV3\n",
    "import watson_developer_cloud \n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "tone_analyzer = ToneAnalyzerV3(\n",
    "    version='2018-08-01',\n",
    "    iam_apikey='KfDInKWxIi8O5nX4eRyX5UiWsQQLnt4xh7MQPy8hKfZu',\n",
    "    url='https://gateway-wdc.watsonplatform.net/tone-analyzer/api'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IBMToneAnalyse(dataquery):\n",
    "    tone_analyzer = ToneAnalyzerV3(\n",
    "    version='2018-08-01',\n",
    "    iam_apikey='KfDInKWxIi8O5nX4eRyX5UiWsQQLnt4xh7MQPy8hKfZu',\n",
    "    url='https://gateway-wdc.watsonplatform.net/tone-analyzer/api'\n",
    ")\n",
    "    \n",
    "    try:\n",
    "        import http.client as http_client\n",
    "    except ImportError:\n",
    "        import httplib as http_client\n",
    "        http_client.HTTPConnection.debuglevel = 1\n",
    "     \n",
    "    json_output = tone_analyzer.tone(dataquery, content_type='text/plain')\n",
    "    Dict_Tone=json_output.get_result()\n",
    "\n",
    "    lst=[]\n",
    "    flag=0\n",
    "\n",
    "    for i in Dict_Tone['document_tone']['tones']:\n",
    "        if (i):\n",
    "            lst.append([\"Tone Name : %s\"%(i['tone_name']),\"Score : %s\" %(i['score']),\"Tone Id : %s\"%(i[\"tone_id\"])])\n",
    "            flag=1\n",
    "        else:\n",
    "            print \"Error: Tone could not be recognised\"\n",
    "    \n",
    "    if flag==1:\n",
    "        return lst\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "IBMsentiment={}\n",
    "for i in dataset:\n",
    "    IBMsentiment[i]=IBMToneAnalyse(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Extremely long waiting time. Food is decent but definitely not worth the wait.': [[u'Tone Name : Confident',\n",
       "   'Score : 0.984417',\n",
       "   u'Tone Id : confident']],\n",
       " 'Fast service. Prices are reasonable and food is decent.': [[u'Tone Name : Analytical',\n",
       "   'Score : 0.883404',\n",
       "   u'Tone Id : analytical']],\n",
       " 'Food is good and not too expensive. Serving is just right. Ambience is nice too.': [[u'Tone Name : Joy',\n",
       "   'Score : 0.7559',\n",
       "   u'Tone Id : joy'],\n",
       "  [u'Tone Name : Tentative', 'Score : 0.944845', u'Tone Id : tentative']],\n",
       " 'Loved the ambience, loved the food': [[u'Tone Name : Joy',\n",
       "   'Score : 0.937302',\n",
       "   u'Tone Id : joy']],\n",
       " 'Mushroom fried rice was tasty': 0,\n",
       " 'Service - Little slow, probably because too many people.': [[u'Tone Name : Sadness',\n",
       "   'Score : 0.709872',\n",
       "   u'Tone Id : sadness'],\n",
       "  [u'Tone Name : Tentative', 'Score : 0.88939', u'Tone Id : tentative'],\n",
       "  [u'Tone Name : Analytical', 'Score : 0.762356', u'Tone Id : analytical']],\n",
       " 'The place is not easy to locate': 0,\n",
       " 'Used to be good. Soup was below average this time.': 0}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IBMsentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using TextBlob pattern analyser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we have the TextBlob python library that is popular for text processing. It has a function for sentiment analysis where it gives the polarity and subjectivity of the concerned text. Negative polarity indicates negative sentiment and positive polarity indicates positive sentiment with the associated text. \n",
    "It has two implementations for analysing sentiments. One is PatternAnalyzer(default) which uses the pattern library and the other is the NaiveBayesAnalyser which is based on Naive Bayes algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TextblobToneAnalyse(dataquery):\n",
    "    blob=TextBlob(dataquery)\n",
    "    sentiment=blob.sentiment\n",
    "    return [sentiment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "Textblobsentiment={}\n",
    "for i in dataset:\n",
    "    Textblobsentiment[i]=TextblobToneAnalyse(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Extremely long waiting time. Food is decent but definitely not worth the wait.': [Sentiment(polarity=-0.011111111111111113, subjectivity=0.3888888888888889)],\n",
       " 'Fast service. Prices are reasonable and food is decent.': [Sentiment(polarity=0.18888888888888888, subjectivity=0.6222222222222222)],\n",
       " 'Food is good and not too expensive. Serving is just right. Ambience is nice too.': [Sentiment(polarity=0.2714285714285714, subjectivity=0.7089285714285715)],\n",
       " 'Loved the ambience, loved the food': [Sentiment(polarity=0.7, subjectivity=0.8)],\n",
       " 'Mushroom fried rice was tasty': [Sentiment(polarity=0.0, subjectivity=0.0)],\n",
       " 'Service - Little slow, probably because too many people.': [Sentiment(polarity=0.004166666666666652, subjectivity=0.4666666666666666)],\n",
       " 'The place is not easy to locate': [Sentiment(polarity=-0.21666666666666667, subjectivity=0.8333333333333334)],\n",
       " 'Used to be good. Soup was below average this time.': [Sentiment(polarity=0.27499999999999997, subjectivity=0.5)]}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Textblobsentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using TextBlob Naive Bayes analyser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Naive Bayes TextBlob analyser classifies the sentiment associated with a sentence as positive, negative. It also gives a probabilistic value for the positive as well as negative sentiment associated with the sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob.sentiments import NaiveBayesAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TextblobNaiveToneAnalyse(dataquery):\n",
    "    blob=TextBlob(dataquery, analyzer=NaiveBayesAnalyzer())\n",
    "    sentiment=blob.sentiment\n",
    "\n",
    "    return [sentiment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextblobNaivesentiment={}\n",
    "for i in dataset:\n",
    "    TextblobNaivesentiment[i]=TextblobNaiveToneAnalyse(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Extremely long waiting time. Food is decent but definitely not worth the wait.': [Sentiment(classification='pos', p_pos=0.5614354038358297, p_neg=0.43856459616417026)],\n",
       " 'Fast service. Prices are reasonable and food is decent.': [Sentiment(classification='neg', p_pos=0.3564904522147827, p_neg=0.6435095477852182)],\n",
       " 'Food is good and not too expensive. Serving is just right. Ambience is nice too.': [Sentiment(classification='neg', p_pos=0.21266962938364903, p_neg=0.7873303706163495)],\n",
       " 'Loved the ambience, loved the food': [Sentiment(classification='neg', p_pos=0.2808623117806499, p_neg=0.7191376882193501)],\n",
       " 'Mushroom fried rice was tasty': [Sentiment(classification='neg', p_pos=0.41625088487702655, p_neg=0.5837491151229747)],\n",
       " 'Service - Little slow, probably because too many people.': [Sentiment(classification='pos', p_pos=0.6535121616454963, p_neg=0.3464878383545031)],\n",
       " 'The place is not easy to locate': [Sentiment(classification='pos', p_pos=0.6508420946901671, p_neg=0.34915790530983226)],\n",
       " 'Used to be good. Soup was below average this time.': [Sentiment(classification='neg', p_pos=0.4015490157906059, p_neg=0.5984509842093945)]}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextblobNaivesentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Vader NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vader function from nltk library can be used for sentiment analysis. It takes a piece of text and gives the neutral, positive and negatve emotion associated with that text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/pranjali/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download(\"vader_lexicon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vaderToneAnalyse(sentence):\n",
    "    nltkSentiment = SentimentIntensityAnalyzer()\n",
    "    sentiment = nltkSentiment.polarity_scores(sentence)\n",
    "    return [sentiment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vadersentiment={}\n",
    "for i in dataset:\n",
    "    Vadersentiment[i]=vaderToneAnalyse(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Extremely long waiting time. Food is decent but definitely not worth the wait.': [{'compound': 0.3718,\n",
       "   'neg': 0.121,\n",
       "   'neu': 0.665,\n",
       "   'pos': 0.215}],\n",
       " 'Fast service. Prices are reasonable and food is decent.': [{'compound': 0.0,\n",
       "   'neg': 0.0,\n",
       "   'neu': 1.0,\n",
       "   'pos': 0.0}],\n",
       " 'Food is good and not too expensive. Serving is just right. Ambience is nice too.': [{'compound': 0.6908,\n",
       "   'neg': 0.0,\n",
       "   'neu': 0.695,\n",
       "   'pos': 0.305}],\n",
       " 'Loved the ambience, loved the food': [{'compound': 0.8316,\n",
       "   'neg': 0.0,\n",
       "   'neu': 0.339,\n",
       "   'pos': 0.661}],\n",
       " 'Mushroom fried rice was tasty': [{'compound': 0.0,\n",
       "   'neg': 0.0,\n",
       "   'neu': 1.0,\n",
       "   'pos': 0.0}],\n",
       " 'Service - Little slow, probably because too many people.': [{'compound': 0.0,\n",
       "   'neg': 0.0,\n",
       "   'neu': 1.0,\n",
       "   'pos': 0.0}],\n",
       " 'The place is not easy to locate': [{'compound': -0.3412,\n",
       "   'neg': 0.286,\n",
       "   'neu': 0.714,\n",
       "   'pos': 0.0}],\n",
       " 'Used to be good. Soup was below average this time.': [{'compound': 0.4404,\n",
       "   'neg': 0.0,\n",
       "   'neu': 0.756,\n",
       "   'pos': 0.244}]}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vadersentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure API "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Microsoft hosted Azure API also supports sentiment analysis. However the authentication process is a little tedious. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Web Services API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AWS text analytics service - Amazon Comprehend also supports sentiment analysis. It requires to create an account with Amazon Web Services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
